### 1、交叉验证

**<font color = #FF0000>使用60%的数据作为训练集，使用 20%的数据作为交叉验证集，使用20%的数据作为测试集</font>**

假设有10个可选模型，则模型选择的方法为：

1. 使用训练集训练出10个模型
2. 用10个模型分别对交叉验证集计算得出**交叉验证误差**（代价函数的值）
3. 选取代价函数值最小的模型
4. 用步骤3中选出的模型对测试集计算得出**推广误差**（代价函数的值）

K折交叉验证中，不重复地随机将训练数据集划分为K个，其中k-1个用于模型的训练，剩余的1个用于测试。重复此过程k次，就得到了k个模型及对模型性能的评价。该种方法对数据划分的敏感性较低。 
 下图展示了k折交叉验证，k=10，训练数据集被划分为10块，在10次迭代中，每次迭代中都将9块用于训练，剩余的1块用于模型的评估。10块数据集作用于某一分类器，分类器得到的性能评价指标为$E_i,i=1,2,⋯,10$，可用来计算模型的估计平均性能$\frac{1}{10} \sum_{i=1}^{10}E_i$

**构建一个机器学习算法的推荐方法为：**

1. 从一个简单的能快速实现的算法开始，实现该算法并用交叉验证集数据测试这个算法
2. 绘制学习曲线，决定是增加更多数据，或者添加更多特征，还是其他选择
3. 进行误差分析：人工检查交叉验证集中我们算法中产生预测误差的样本，看看这些样本是否有某种系统化的趋势

### 2、欠拟合和过拟合

如果我们的交叉验证集误差较大，我们如何判断是方差还是偏差呢？

- 训练集误差和交叉验证集误差近似时：偏差/欠拟合
- 交叉验证集误差远大于训练集误差时：方差/过拟合

### 3、正则项与误差

![](../images/38eed7de718f44f6bb23727c5a88bf5d.png)

• 当 $\lambda$ 较小时，训练集误差较小（过拟合）而交叉验证集误差较大

• 随着 $\lambda$ 的增加，训练集误差不断增加（欠拟合），而交叉验证集误差则是先减小后增加

### 4、学习曲线

![img](..\images\6_10_1.png) 

注意上图，高偏差和高方差曲线的区别：

**高方差：**

随着训练数据集的增多，模型在训练数据集和交叉验证数据集上的得分（对于回归问题为拟合优度）逐渐靠近。但两者得分整体比较低。

过拟合问题的解决方法

- 获取更多的训练数据：从上面右图来看，更多的训练数据有助于解决过拟合问题
- 减少输入的特征数量：减少特征数量可以减少模型的复杂度

**高偏差：**

随着训练数据集的增多，模型在交叉验证数据集上的得分逐渐和在训练数据集上的得分靠近，但两者之间的间隙仍然比较大。

欠拟合问题的解决方法

- 增加有价值的特征
- 增加多项式特征

**总结：解决高方差和高偏差的方法：**

1. 获得更多的训练样本——解决高方差
2. 尝试减少特征的数量——解决高方差
3. 尝试获得更多的特征——解决高偏差
4. 尝试增加多项式特征——解决高偏差
5. 尝试减少正则化程度λ——解决高偏差
6. 尝试增加正则化程度λ——解决高方差

```
神经网络中的方差和偏差：

使用较小的神经网络，类似于参数较少的情况，容易导致高偏差和欠拟合，但计算代价较小使用较大的神经网络，类似于参数较多的情况，容易导致高方差和过拟合，虽然计算代价比较大，但是可以通过正则化手段来调整而更加适应数据。
通常选择较大的神经网络并采用正则化处理会比采用较小的神经网络效果要好。
```

### 5、查全率和查准率

![1537944867334](..\images\1537944867334.png)

### 6、ROC曲线

Class为正确分类，Score为分类器的概率，按从大到小排列

![1537946993249](..\images\1537946993249.png)

对每个Score设置为阈值，计算其True postive rate（**预测为正且实际为正**的样本占**所有正例样本**的比例 ）和False postive rate（**预测为正但实际为负**的样本占**所有负例样本**的比例 ）。比如当阈值为0.6，则True postive rate= 3/10 = 0.3，False postive rate = 1/10 = 0.1。

![1537947021453](..\images\1537947021453.png)

![img](..\images\1537947368839.png) 

7、